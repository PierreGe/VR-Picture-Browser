\documentclass[11pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{todonotes}
\usepackage{lscape}
\usepackage{cite}
\usepackage{hyperref}
\usepackage{afterpage}
\author{Pierre Gerard - Matteo Marra - Bruno Rocha Pereira}
\title{Given One \\ Intelligent Picture Browser \\ Requirements and Analysis report}
\date{December 19, 2016}

\begin{document}

\maketitle

\section{Introduction}

New generation user interfaces are developing day by day, with new tools, devices and different use cases showing up.

Of those devices, Virtual Reality sets are expanding as those devices get more affordable and many research team started working on it. 

Our brainstorming led to us imagining a future where we would use Virtual Reality on common basis, we thought about what an user would like to have and that doesn't exist yet, and how to implement it to make the user feel comfortable in this totally new environment. 

The system will offer the user a collection of pictures in a Virtual Reality environment, allowing him to browse them intelligently.

\section{Problem to be solved}

Since the numeric revolution, humans tend to take a ton of pictures. It is especially true during their holidays, usually coming back with thousands of pictures. The problem that arise then is that human don't usually have a mean to explore them all other than browsing through them one by one. So, the idea for the project is to create a \textit{Intelligent Picture Browser (IPB)} to fill that void.

\section{Requirement Analysis}

The product should browse the user complete gallery of pictures and select a subset of them. The subset selection will be based on a keyword/tag selection. The keyword/tag is automatically linked to pictures by a AI algorithm.

The user will be able to interact with the interface trough the virtual reality set and be able to select tag and some settings via voice.

\subsection{Data requirements}

The interface should work with any set of pictures in a \textit{jpg} format. However for testing and demonstration purpose, a preloaded set of 300 holiday pictures will be available

\subsection{User characteristics}

The interface will be design to fit almost every individual having the capacity to use a virtual reality set and voice recognition. It will target technological novice as well as professional. Unfortunately, people with disabilities preventing them from using a VR set or voice recognition won't be able to use our system.

\subsection{Usability goals}

The usability of this project is going to be as much as straightforward as possible and will not require any particular skill or educational background. However having a regular access to technologies and computers will be a plus for a smoother use. In brief, it should be easy to learn, efficient and effective.
% requirement on our ngui in particukar

\subsection{User experience goals}

The main goal is to make the user relive the moment immortalized by the pictures and helping him remember the event and feel the same emotion once again. % user should feel that it is useful enjoyable, engaging and FUN

\section{Design and prototyping}

For the design, implementation and validation of the next generation user interface, we worked in an iterative way.
The idea was to create multiple evolutionary prototyping. Each prototype was then presented to the class. With such a method, we were able to create a final product on time and validated its usability.

\subsection{Iteration 1 : problem defined}

The first iteration consisted mainly on sitting in a confortable room and brainstorming about which next-generation interface to design. Many idea had emerged and the one that convince us the most was to innovate in the picture browsing field. Indeed, multiple technologies have recently appears on the market and we though they could be use to enhance usability and user experience of such systems.
The first and main assumption made on behalf of the user is that the user possess a lot of picture but don't have the time of to browse or sort them all. We want to solve this user's problem.
The added value of our idea to traditional iterative picture browser was an intelligence which recognize effortlessly the content of user's pictures and immersive way to browse them thanks to new immersive technology known as virtual reality and voice recognition.

\subsection{Iteration 2 : requirements defined}

% define the requirements

% user-centred design involves users throughout the process

% planning, deadlining

\subsection{Iteration 3 : low-fidelity prototype}

This iteration was all about making sure the product is feasible and that requirements could be reached by making a low-fidelity prototype with all components working separately.
The idea here was to find solution for each of those components :
\begin{itemize}
	\item A Neural Network capable of automatically tagging the image,
	\item A framework to support the HTV Vive Virtual reality set,
	\item A Speech recognizer interoperable with the chosen VR framework,
\end{itemize}

More information about the technologies used can be find in architecture section \ref{techntechno} .

\subsection{Iteration 4 : high fidelity prototype}

The goal of this iteration was to managed to build a working high-fidelity prototype were the main feature of the interface would be there.
The prototype build at this point was capable of handling voice recognized keywords and showed the corresponding image in the Virtual Reality environment.

\subsection{Iteration 5 : prototype improvement}

This iteration focused on user goals and on usability trough improvement of the first high-fidelity prototype. Following users feedback, we changed the way the picture are displayed : instead of showing a "wall" of pictures we surround the user with picture, making a circle of pictures around the user.
We also added more advanced queries, where a user can do the union and the intersection of subsets (tags) of pictures.

\subsection{Iteration 6 : final product}

% improvement (display of tag suggestion, pictures moving toward a farther, selecting pictures, moving upward and downward, minor)

% usability

% we add visibility (of feature)

% natural mapping (of action to do function)

% feedback (if i look at a picture it get slightly bigger

% evaluation


\section{Technical : Intelligent Picture Browser}


% first clearly defined product wanted and requirement, iterative evolutionary prototyping with refinement PoC until an evaluted final product, we followed the init gant chart

% here insert iterative pictures of our system

\subsection{Interactions}

% voice recognition for tag and non-vive-command intuite interaction
% for intuitive interaction

\subsection{Architecture} \label{techntechno}


The selected technologies are :
\begin{itemize}
	\item Google machine learning library TensorFlow for the neural network,
	\item Microsoft .net speech recognition library for the voice recognition
	\item Unity3D for the HTC Vive Virtual Reality environment.
\end{itemize}


% NN for tag -> json

% Utinty interface <- json
% unity interface <- win10 speech recognizer


\subsection{Challenges}

% use unity and all its specificities

% poor software interoperability, as a result our project only work on win 10

% making the function visible

% VR new and doc is bad

% require a monster computer

\subsection{Evaluation}

% usability testing -> ensure that user can use the product and they like it . 

% Student in CS and non-tech guy with no previous knwoledge on our product.

% Evalution take place in front of computer in natural setting

% summative evalution -> assess the final product. How well did we do ?


\section{Conclusion}


\end{document}




